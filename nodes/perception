#!/usr/bin/env python
import cv2
import rospy
import mediapipe as mp
from cv_bridge import CvBridge
from std_msgs.msg import String
from rockpaperscissors.msg import Choices
import math

drawingModule = mp.solutions.drawing_utils
handsModule = mp.solutions.hands

capture = cv2.VideoCapture(0)
 
frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)
frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)

font = cv2.FONT_HERSHEY_SIMPLEX

bridge = CvBridge()

human_score = 0
robot_score = 0

human_choice = "none"
robot_choice = "none"

def choiceCallback(choices):
    global human_score
    global robot_score

    global human_choice
    global robot_choice
    human_choice = choices.human_choice
    robot_choice = choices.robot_choice

    if robot_choice == "rock" and human_choice == "scissors":
        robot_score += 1
    elif robot_choice == "paper" and human_choice == "rock":
        robot_score += 1
    elif robot_choice == "scissors" and human_choice == "paper":
        robot_score += 1
    elif robot_choice == "scissors" and human_choice == "rock":
        human_score += 1
    elif robot_choice == "rock" and human_choice == "paper":
        human_score += 1
    elif robot_choice == "paper" and human_choice == "scissors":
        human_score += 1

if __name__ == '__main__':
    rospy.init_node('perception')

    pub = rospy.Publisher('human_gesture', String, queue_size=10)
    rospy.Subscriber("choices", Choices, choiceCallback)
    rate = rospy.Rate(10) # 10hz

    gesture = "NONE"

    start_timer = 0
    amcounting = True
    pause_time = 0
    timer = 0
    human_decided = False

    with handsModule.Hands(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=2) as hands:

        while (capture.isOpened()):

            ret, frame = capture.read()
            # frame = cv2.resize(frame, [frame.shape[1]*2, frame.shape[0]*2])
            frame = cv2.resize(frame, [frame.shape[1], frame.shape[0]])

            results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

            if results.multi_hand_landmarks != None:
                for handLandmarks in results.multi_hand_landmarks:
                    drawingModule.draw_landmarks(frame, handLandmarks, handsModule.HAND_CONNECTIONS) # Draws connecting lines between landmarks
                
                palm_base = [handLandmarks.landmark[0].x, handLandmarks.landmark[0].y]

                thumb_finger_tip = [handLandmarks.landmark[4].x, handLandmarks.landmark[4].y]
                thumb_finger_knuckle = [handLandmarks.landmark[2].x, handLandmarks.landmark[2].y]

                index_finger_tip = [handLandmarks.landmark[8].x, handLandmarks.landmark[8].y]
                index_finger_knuckle = [handLandmarks.landmark[5].x, handLandmarks.landmark[5].y]

                middle_finger_tip = [handLandmarks.landmark[12].x, handLandmarks.landmark[12].y]
                middle_finger_knuckle = [handLandmarks.landmark[9].x, handLandmarks.landmark[9].y]

                ring_finger_tip = [handLandmarks.landmark[16].x, handLandmarks.landmark[16].y]
                ring_finger_knuckle = [handLandmarks.landmark[13].x, handLandmarks.landmark[13].y]

                pinky_finger_tip = [handLandmarks.landmark[20].x, handLandmarks.landmark[20].y]
                pinky_finger_knuckle = [handLandmarks.landmark[17].x, handLandmarks.landmark[17].y]

                S = 0.5
                R = 2

                index_slope = math.atan2(index_finger_tip[1] - index_finger_knuckle[1], index_finger_tip[0] - index_finger_knuckle[0])
                middle_slope = math.atan2(middle_finger_tip[1] - middle_finger_knuckle[1], middle_finger_tip[0] - middle_finger_knuckle[0])
                angle = abs((middle_slope - index_slope) / (1 + index_slope * middle_slope))
                deg = (math.atan(angle) * 180) / 3.14159

                if start_timer < 4:
                    if palm_base[1] > 0.6 and amcounting == True:
                        start_timer += 1
                        amcounting = False
                    elif palm_base[1] < 0.6 and amcounting == False:
                        amcounting = True
                    
                    pause_time = 0

                elif start_timer == 4 and pause_time < 6:
                    pause_time += 1

                elif start_timer == 4 and pause_time >= 6:
                    # check gesture for rock, paper, scissors
                    if (math.dist(index_finger_tip, index_finger_knuckle)*S > math.dist(ring_finger_tip, ring_finger_knuckle) and
                        math.dist(index_finger_tip, index_finger_knuckle)*S > math.dist(pinky_finger_tip, pinky_finger_knuckle) and
                        math.dist(middle_finger_tip, middle_finger_knuckle)*S > math.dist(ring_finger_tip, ring_finger_knuckle) and
                        math.dist(middle_finger_tip, middle_finger_knuckle)*S > math.dist(pinky_finger_tip, pinky_finger_knuckle) and
                        deg > 20):
                        if gesture != "scissors":
                            gesture = "scissors"
                            pub.publish(gesture)
                            human_decided = True
                            timer = 0
                    elif math.dist(index_finger_knuckle, pinky_finger_knuckle) < math.dist(index_finger_tip, index_finger_knuckle)*0.5:
                        if gesture != "paper":
                            gesture = "paper"
                            pub.publish(gesture)
                            human_decided = True
                            timer = 0
                    elif (math.dist(index_finger_tip, index_finger_knuckle)*R < math.dist(index_finger_knuckle, palm_base) and
                        math.dist(middle_finger_tip, middle_finger_knuckle)*R < math.dist(middle_finger_knuckle, palm_base) and
                        math.dist(ring_finger_tip, ring_finger_knuckle)*R < math.dist(ring_finger_knuckle, palm_base) and
                        math.dist(pinky_finger_tip, pinky_finger_knuckle)*R < math.dist(pinky_finger_knuckle, palm_base)):
                        if gesture != "rock":
                            gesture = "rock"
                            pub.publish(gesture)
                            human_decided = True
                            timer = 0
                    else:
                        if gesture != "NONE":
                            gesture = "NONE"
                    
                    start_timer = 0
            else:
                if gesture != "NONE":
                    gesture = "NONE"

            green = (0, 150, 0)
            purple = (132, 42, 78)
            black = (0, 0, 0)
            white = (255, 255, 255)
                            
            # cv2.putText(frame, gesture, (50, 90), font, 1, (132, 42, 78), 3, cv2.LINE_4)
            cv2.putText(frame, str(start_timer), (50, 90), font, 1, green, 3, cv2.LINE_4)

            cv2.putText(frame, "HUMAN", (50, 350), font, 1, black, 6, cv2.LINE_4)
            cv2.putText(frame, "HUMAN", (50, 350), font, 1, white, 2, cv2.LINE_4)

            cv2.putText(frame, str(human_score), (80, 410), font, 2, black, 10, cv2.LINE_4)
            cv2.putText(frame, str(human_score), (80, 410), font, 2, white, 3, cv2.LINE_4)

            cv2.putText(frame, "ROBOT", (480, 350), font, 1, black, 6, cv2.LINE_4)
            cv2.putText(frame, "ROBOT", (480, 350), font, 1, white, 2, cv2.LINE_4)

            cv2.putText(frame, str(robot_score), (510, 410), font, 2, black, 10, cv2.LINE_4)
            cv2.putText(frame, str(robot_score), (510, 410), font, 2, white, 3, cv2.LINE_4)


            if human_decided == True:
                cv2.putText(frame, str(human_choice), (50, 290), font, 1, black, 6, cv2.LINE_4)
                cv2.putText(frame, str(human_choice), (50, 290), font, 1, green, 2, cv2.LINE_4)
                cv2.putText(frame, str(robot_choice), (480, 290), font, 1, black, 6, cv2.LINE_4)
                cv2.putText(frame, str(robot_choice), (480, 290), font, 1, green, 2, cv2.LINE_4)
                timer += 1
            
            if timer >= 40:
                timer = 0
                human_decided = False

            cv2.imshow('Gesture Recognition', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        capture.release()
        cv2.destroyAllWindows()
